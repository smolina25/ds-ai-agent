{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "93531130",
      "metadata": {},
      "source": [
        "# ðŸ§  AI Agents\n",
        "\n",
        "This notebook demonstrates how to build a **LangChain agent** with multiple tools.\n",
        "\n",
        "---\n",
        "\n",
        "## ðŸ” What is an Agent?\n",
        "\n",
        "An **agent** is like an intelligent assistant that:\n",
        "1. Thinks about the user's request (**Thought**)\n",
        "2. Decides what tool(s) to use (**Action**)\n",
        "3. Executes the tool(s) and observes results (**Observation**)\n",
        "4. Returns the final response (**Final Answer**)\n",
        "\n",
        "This is based on the **ReAct framework** (Reason + Act), which gives LLMs structured reasoning steps.\n",
        "\n",
        "This means that ReAct agents can:\n",
        "- **Think** about the task\n",
        "- **Act** by calling tools\n",
        "- **Observe** the results of their actions\n",
        "\n",
        "---\n",
        "\n",
        "## ðŸ”§ What are Tools?\n",
        "\n",
        "- Tools are **functions** (APIs, calculators, web search, etc.) that the agent can call.\n",
        "- Each tool has:\n",
        "  - A **name**\n",
        "  - A **description** (so the agent knows when to use it)\n",
        "  - A **function** that does the actual work\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1bb9da26",
      "metadata": {},
      "outputs": [],
      "source": [
        "from dotenv import load_dotenv\n",
        "import warnings\n",
        "from langchain_groq import ChatGroq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "88b7bdac",
      "metadata": {},
      "outputs": [],
      "source": [
        "# load environment variables from .env file\n",
        "load_dotenv()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c954138c",
      "metadata": {},
      "source": [
        "### Different Models which can be used"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "96d733be",
      "metadata": {},
      "source": [
        "[Here](https://console.groq.com/docs/deprecations) you will find all the models available other than which are listed below."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cb132fc0",
      "metadata": {},
      "source": [
        "| Model                   | Size / Type        | Context Window | Strengths                                                                 | Best Use Cases                                      |\n",
        "|--------------------------|-------------------|----------------|---------------------------------------------------------------------------|----------------------------------------------------|\n",
        "| **gemma2-9b-it**         | 9B, instruction-tuned | 8K             | Googleâ€™s Gemma v2 instruction-tuned model. Good at following prompts, lightweight compared to 70B models. | Small-to-mid agents, lightweight reasoning, fine for simple tool use with prompting. |\n",
        "| **llama-3.3-70b-versatile** | 70B, general versatile | 8K             | Metaâ€™s flagship Llama 3.3 model hosted on Groq. High reasoning quality, supports structured outputs and function calling. | Complex agents, production-grade apps, when you need reliability and accuracy. |\n",
        "| **llama-3.1-8b-instant** (not working in this example)   | 8B, fast & compact | 128K           | Optimized for **speed** with large 128K context window. Supports JSON mode and function calling, very low latency. | Real-time apps, chatbots, smaller agents where fast responses matter. |\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c8ba04ad",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get llms models via the `langchain_groq` package\n",
        "llm_model = ChatGroq(\n",
        "    model=\"llama-3.3-70b-versatile\", #llama-3.3-70b-versatile\",\n",
        "    temperature=0,\n",
        "    max_tokens=512,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3336df6f",
      "metadata": {},
      "source": [
        "### Defining Tools ðŸ”¨\n",
        "We want to equip our agent with 2 simple custome-made tools:\n",
        "1. **MathTool**: Solves math expressions using Python's `eval()`.\n",
        "2. **LengthTool**: Counts the number of characters in a string."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6922ad25",
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain.tools import Tool\n",
        "from langchain.agents import initialize_agent, AgentType\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "748bc547",
      "metadata": {},
      "source": [
        "##### Custome-made Tool 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cc46c1be",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Tool 1\n",
        "def math_calculator(input_string: str) -> str:\n",
        "    \"\"\"A simple calculator tool that performs arithmetic operations.\"\"\"\n",
        "    # Evaluate the input string as a mathematical expression    \n",
        "    result = eval(input_string)\n",
        "    return f\"The result is: {result}\"\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e062df86",
      "metadata": {},
      "outputs": [],
      "source": [
        "math_tool = Tool(\n",
        "    name=\"MathTool\", # Name of the tool\n",
        "    func=math_calculator, # Function to call\n",
        "    description=\"Use this tool to solve basic math problems. Input should be a valid math expression like '8 * 12'.\" # Description of the tool\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1ed0abca",
      "metadata": {},
      "source": [
        "##### Custom Tool 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9ae1428d",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Tool 2\n",
        "def string_length(input_string: str) -> str:\n",
        "    \"\"\"A tool to count the number of characters in a string.\"\"\"\n",
        "    length = len(input_string)\n",
        "    return f\"The length of the string is: {length} characters.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a7de65af",
      "metadata": {},
      "outputs": [],
      "source": [
        "length_tool = Tool(\n",
        "    name=\"LengthTool\",\n",
        "    func=string_length,\n",
        "    description=\"Use this tool to count the number of characters in a string.\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3d25ee9e",
      "metadata": {},
      "source": [
        "> __Very important__:\n",
        "> \n",
        ">  Add __clear descriptions__ for each tools ðŸ› ï¸!!!\n",
        "> \n",
        "> The agent **doesn't know how the tools work internally**.  \n",
        "> \n",
        "> It relies entirely on the tool's **name** and **description** to decide when to use them."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b1305dbe",
      "metadata": {},
      "source": [
        "### Initialize the Agent\n",
        "We create a type of agent called `zero-shot-react-description`, which means:\n",
        "- It uses the **ReAct** reasoning framework:\n",
        "  - **Thought**: Decide what to do\n",
        "  - **Action**: Pick a tool\n",
        "  - **Observation**: See the tool's output\n",
        "  - Repeat until it has the **Final Answer**\n",
        "- **Zero-shot** means the agent doesn't need any examples.  \n",
        "  It figures out how to use tools **just from their descriptions**."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5d3fff15",
      "metadata": {},
      "source": [
        "##### ðŸ§  LangChain Agent Types â€” Overview\n",
        "\n",
        "| AgentType | Description | Best For / Use Case |\n",
        "|-----------|-------------|---------------------|\n",
        "| `AgentType.ZERO_SHOT_REACT_DESCRIPTION` | Classic ReAct-style agent. Chooses tools by reasoning step-by-step from scratch using only descriptions. | Simple tool use, when you want the agent to figure out how to solve tasks on its own. |\n",
        "| `AgentType.CHAT_ZERO_SHOT_REACT_DESCRIPTION` | Same as above, but optimized for chat models (e.g., gpt-3.5-turbo). Uses `ChatPromptTemplate`. | Chat-based apps with tool use. |\n",
        "| `AgentType.REACT_DOCSTORE` | Uses ReAct logic, but built for interacting with a single knowledge base (like Wikipedia). | Agents that need to read docs or search a single data source. |\n",
        "| `AgentType.SELF_ASK_WITH_SEARCH` | Specialized agent for answering factual questions. Agent asks itself sub-questions, then answers them using a search tool. | Fact-based Q&A (like \"What year did X happen?\"). Often paired with web search. |\n",
        "| `AgentType.CONVERSATIONAL_REACT_DESCRIPTION` | Like `ZERO_SHOT_REACT_DESCRIPTION`, but keeps track of conversation history (with memory). | Conversational agents using tools. Good for chatbots. |\n",
        "| `AgentType.CHAT_CONVERSATIONAL_REACT_DESCRIPTION` | Chat version of the above. Uses `ChatPromptTemplate` with memory and tool reasoning. | Best for multi-turn chats + tools. |\n",
        "| `AgentType.OPENAI_FUNCTIONS` | Uses OpenAI's function calling (like GPT-4 tools API). LLM chooses tool via function schema. | If you're using OpenAI and want tools selected via native function-calling interface. |\n",
        "| `AgentType.STRUCTURED_CHAT_ZERO_SHOT_REACT_DESCRIPTION` | Newer ReAct-like chat agent that formats output as JSON (structured actions). Works well with function schemas. | When you want tool calls to be structured and parsable (e.g., APIs, apps). |\n",
        "| `AgentType.OPENAI_MULTI_FUNCTIONS` | Same as `OPENAI_FUNCTIONS`, but allows calling **multiple tools at once**. | Advanced OpenAI workflows needing multi-function execution. |\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "11b5d8ee",
      "metadata": {},
      "outputs": [],
      "source": [
        "dir(AgentType)[:9]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "20e8cd52",
      "metadata": {},
      "outputs": [],
      "source": [
        "langchain_agent = initialize_agent(\n",
        "    tools=[math_tool, length_tool], # List of tools to use\n",
        "    llm=llm_model, # The language model to use\n",
        "    agent_type=AgentType.ZERO_SHOT_REACT_DESCRIPTION, # Type of agent to create\n",
        "    verbose=True, # Whether to print out the agent's reasoning\n",
        "    max_iterations=3, # Maximum number of iterations for the agent\n",
        "    return_intermediate_steps=False, # Whether to return intermediate steps\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "75597f70",
      "metadata": {},
      "source": [
        "### Run the Agent ðŸ¤–"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3b61539b",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Example 1: Math question\n",
        "print(\"---- Math Question ----\")\n",
        "response = langchain_agent.invoke(\"What is 15 * 4?\")\n",
        "print(\"âœ… Final Answer:\", response)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "439306cf",
      "metadata": {},
      "source": [
        "The output shows the agent's chain of reasoning:\n",
        "+ tought: reasoning steps\n",
        "+ action: which tool it chose\n",
        "+ observation: the result of the tool call"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f1527734",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Example 2: String length question\n",
        "print(\"\\n---- String Length Question ----\")\n",
        "response = langchain_agent.invoke(\"How many characters are in the string '' ?\")\n",
        "print(\"âœ… Final Answer:\", response['output'])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0345d85b",
      "metadata": {},
      "source": [
        "## Summary\n",
        "- Agents are intelligent assistants that can think, act, and observe.\n",
        "- They use tools to perform tasks.\n",
        "- LangChain provides a framework for building agents with structured reasoning.\n",
        "- You can create custom tools and define how the agent should use them."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
