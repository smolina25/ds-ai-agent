{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "36568748",
   "metadata": {},
   "source": [
    "# Langchain Agents \n",
    "This notebook demonstrates how to create and use agents in Langchain, including the use of tools like DuckDuckGoSearch for real-time information retrieval.\n",
    "\n",
    "At the end of this notebook, we can see how to create a ReAct agent from a prompt template and use it with a memory system to maintain chat history.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c24b09d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from langchain_groq import ChatGroq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a99eb1ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load environment variables from .env file\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da210b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get llms models via the `langchain_groq` package\n",
    "llm_model = ChatGroq(\n",
    "    model=\"llama-3.3-70b-versatile\", #llama-3.3-70b-versatile\",\n",
    "    temperature=.5,\n",
    "    max_tokens=512,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04737fc7",
   "metadata": {},
   "source": [
    "## Langchain Tools\n",
    "\n",
    "The [third-party tools](https://python.langchain.com/docs/integrations/tools/) from the langchain-community ecosytem allow us to extent the capabilities of our agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5079babb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_community.tools import DuckDuckGoSearchRun\n",
    "from ddgs import DDGS\n",
    "from langchain_community.utilities import DuckDuckGoSearchAPIWrapper"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82f275e7",
   "metadata": {},
   "source": [
    "`DuckDuckGoSearchRun` allows us to perform web searches and retrieve information in real-time, which can be very useful for agents that need to answer questions based on current data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dcb9e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "#api_wrapper = DuckDuckGoSearchAPIWrapper(region=\"en-en\",max_results=10)\n",
    "#search = DuckDuckGoSearchRun()#,api_wrapper=api_wrapper)\n",
    "\n",
    "def ddg_search(query: str):\n",
    "    with DDGS() as ddgs:\n",
    "        return ddgs.text(query, max_results=5)\n",
    "search = ddg_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c322e7d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = search(\"Prime Italian Minister\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea55bad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89951384",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a tool for the DuckDuckGo search\n",
    "from langchain.tools import Tool\n",
    "search_tool = Tool(\n",
    "    name=\"DuckDuckGoSearch\",\n",
    "    func=ddg_search,\n",
    "    description=\"Use this tool when you need to search for real-time information from DuckDuckGo.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf6c35b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import initialize_agent, AgentType\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a2c74b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the agent with the DuckDuckGo search tool\n",
    "agent = initialize_agent(\n",
    "    tools=[search_tool],\n",
    "    llm=llm_model,\n",
    "    agent_type=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    verbose=True,\n",
    "    max_iterations=7,\n",
    "    agent_name=\"DuckDuckGoSearchAgent\",\n",
    "    agent_description=\"An agent that can search the web using DuckDuckGoSearch and summarize findings clearly.\"\n",
    ")\n",
    "\n",
    "# Now we can use the agent to answer questions\n",
    "results = agent.invoke(\"Who is the Italian Prime Minister?\")  # Example query to the agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dded966a",
   "metadata": {},
   "source": [
    "### Create a an Agent with DuckDuckGoSearch with Memory\n",
    "In this section, we will create an agent that can search the web using DuckDuckGoSearch and maintain a memory of previous interactions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db9ed789",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "267eb34b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Build a chat prompt that includes conversation history so the agent can resolve references.\n",
    "prompt_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"\"\"Answer the following questions as best you can. You have access to the following tools:\n",
    "{tools}\n",
    "Use the following format:\n",
    "\n",
    "Question: the input question you must answer\n",
    "Thought: you should always think about what to do\n",
    "Action: the action to take, should be one of [{tool_names}]\n",
    "Action Input: the input to the action\n",
    "Observation: the result of the action\n",
    "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
    "Thought: I now know the final answer\n",
    "Final Answer: the final answer to the original input question\n",
    "\n",
    "Begin!\"\"\"),\n",
    "    MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "    (\"human\", \"{input}\"),\n",
    "    (\"assistant\", \"{agent_scratchpad}\"),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0318ffad",
   "metadata": {},
   "source": [
    "The react_template instructs the laguage model to:\n",
    "1. __Think__ about how to solve a user's question\n",
    "2. __Use tools__ (actions) to gather mor information or perform actions\n",
    "3. __Observe results__ and update the its thoughts\n",
    "4. Eventually, reach a __Final Answer__\n",
    "\n",
    "The following is the explanation of the `react_template` used to create the agent:\n",
    "\n",
    "```python\n",
    "react_template = \"\"\"\n",
    "'Answer the following questions as best you can. You have access to the following tools:\n",
    "\n",
    "{tools}\n",
    "```\n",
    "+ Introduce the agent and tells it what tools it can use\n",
    "+ {tools} is a placeholder for the tools that will be used by the agent\n",
    "\n",
    "```text\n",
    "Use the following format:\n",
    "\n",
    "Question: the input question you must answer\n",
    "Thought: you should always think about what to do\n",
    "Action: the action to take, should be one of [{tool_names}]\n",
    "Action Input: the input to the action\n",
    "Observation: the result of the action\n",
    "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
    "Thought: I now know the final answer\n",
    "Final Answer: the final answer to the original input question\n",
    "```\n",
    "\n",
    "This is the strict __format__ the LLM must follow to:\n",
    "\n",
    "* Show its reasoning (Thought)\n",
    "\n",
    "* Choose and execute a tool (Action)\n",
    "\n",
    "* Feed it input (Action Input)\n",
    "\n",
    "* Observe results (Observation)\n",
    "\n",
    "* Loop until it gets to the final answer\n",
    "\n",
    "```text\n",
    "Begin!\n",
    "Question: {input}\n",
    "Thought:{agent_scratchpad}'\n",
    "\"\"\"\n",
    "```\n",
    "+ `{input}` is the actual user question.\n",
    "\n",
    "+ `{agent_scratchpad}` holds any intermediate steps already completed (e.g., previous Thoughts, Actions, Observations).\n",
    "\n",
    "+ The agent continues from this point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e4a2af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt_template defined above with chat history support\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74af668f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import AgentExecutor, create_react_agent\n",
    "from langchain.memory import ChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f18ac356",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple session store to keep track of chat history per conversation\n",
    "store = {}\n",
    "\n",
    "\n",
    "def get_session_history(session_id: str):\n",
    "    if session_id not in store:\n",
    "        store[session_id] = ChatMessageHistory()\n",
    "    return store[session_id]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d133ee79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the agent \n",
    "agent = create_react_agent(llm_model, [search_tool], prompt_template)\n",
    "agent_executor = AgentExecutor(\n",
    "    agent=agent,\n",
    "    tools=[search_tool],\n",
    "    verbose=True,\n",
    "    handle_parsing_errors=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dfb714a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrap the agent executor with message history\n",
    "agent_with_chat_history = RunnableWithMessageHistory(\n",
    "    agent_executor,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"input\",\n",
    "    history_messages_key=\"chat_history\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ecc7b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we can use the agent with chat history to answer questions\n",
    "agent_with_chat_history.invoke(\n",
    "    {\"input\": \"How many people live in italy?\"},\n",
    "    config={\"configurable\": {\"session_id\": \"1\"}},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b28e9e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's ask another question to see how the agent uses the chat history\n",
    "agent_with_chat_history.invoke(\n",
    "    {\"input\": \"what is their national anthem called?\"},\n",
    "    config={\"configurable\": {\"session_id\": \"1\"}},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6bb8573",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "Create or Select some tools from the [langchain-community tools](https://docs.langchain.com/oss/python/integrations/tools) and create a ReAct agent that can use them to solve certain tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f495342",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
